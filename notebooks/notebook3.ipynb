{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cikm2021-tutorial-part3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9egyhuvU3_GI"
      },
      "source": [
        "# PyTerrier CIKM 2021 Tutorial Notebook - Part 3 - Neural Re-Ranking and Neural Index Augmentation\n",
        "\n",
        "This is one of a series of Colab notebooks created for the [CIKM 2021](https://www.cikm2021.org/) Tutorial entitled '**IR From Bag-of-words to BERT and Beyond through Practical Experiments**'. It demonstrates the use of [PyTerrier](https://github.com/terrier-org/pyterrier) on the [CORD19 test collection](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge).\n",
        "\n",
        "In particular, in this notebook you will:\n",
        "\n",
        " - Re-rank documents using neural models like KNRM, Vanilla BERT, EPIC, and monoT5.\n",
        " - Use DeepCT and doc2query to augment documents for lexical retrieval functions like BM25."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dl0-Gs6e5I7n"
      },
      "source": [
        "## Setup\n",
        "\n",
        "In the following, we will set up the libraries required to execute the notebook.\n",
        "\n",
        "### Pyterrier installation\n",
        "\n",
        "The following cell installs the latest release of the [PyTerrier](https://github.com/terrier-org/pyterrier) package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSgDzjKxqfq5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "812f9714-c5c0-46ad-b851-be45e10908ff"
      },
      "source": [
        "!pip install -q --upgrade python-terrier"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.4/163.4 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m859.0/859.0 kB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.0/288.0 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.2/119.2 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for chest (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for warc3-wet-clueweb09 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for cbor (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mV0C6jJvqhMR"
      },
      "source": [
        "### Pyterrier plugins installation\n",
        "\n",
        "We install the [OpenNIR](https://opennir.net/), [monoT5](https://github.com/terrierteam/pyterrier_t5), [DeepCT](https://github.com/terrierteam/pyterrier_deepct) and [doc2query](https://github.com/terrierteam/pyterrier_doc2query) PyTerrier plugins. You can safely ignore the package versioning errors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkIR_PXdet7R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50fcaa72-2141-4b07-9618-399212cfc383"
      },
      "source": [
        "!pip install -q --upgrade git+https://github.com/Georgetown-IR-Lab/OpenNIR\n",
        "!pip install -q --upgrade git+https://github.com/terrierteam/pyterrier_t5\n",
        "!pip install -q --upgrade git+https://github.com/terrierteam/pyterrier_deepct.git\n",
        "!pip install -q --upgrade git+https://github.com/terrierteam/pyterrier_doc2query.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.7/74.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.3/114.3 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.1/158.1 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.8/84.8 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for OpenNIR (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyterrier-t5 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyterrier-deepct (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for DeepCT (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyterrier-doc2query (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-nQrpNP5pN7"
      },
      "source": [
        "## Preliminary steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSUwC6S7QkQY"
      },
      "source": [
        "**[PyTerrier](https://github.com/terrier-org/pyterrier) initialization**\n",
        "\n",
        "Lets get [PyTerrier](https://github.com/terrier-org/pyterrier) started. This will download the latest version of the [Terrier](http://terrier.org/) IR platform. We also import the [OpenNIR](https://opennir.net/) pyterrier bindings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FegcyWr5lja",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cadfd5d-b7f4-4f78-e061-3e7ae5349d57"
      },
      "source": [
        "# First, install and import PyTerrier\n",
        "# !pip install python-terrier\n",
        "import pyterrier as pt\n",
        "# Initialize PyTerrier\n",
        "if not pt.started():\n",
        "    pt.init()\n",
        "\n",
        "# Set up paths\n",
        "index_dir = \"./fiqa_index\"\n",
        "fiqa_data_path = \"./output\"  # Adjust to your actual path\n",
        "\n",
        "# Function to generate document dictionaries from FIQA\n",
        "def fiqa_document_generator():\n",
        "    # You'll need to adjust this based on your FIQA data format\n",
        "    # Here's an example assuming you have a JSON file with documents\n",
        "    import json\n",
        "    with open(\"/content/corpus.jsonl\", 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            try:\n",
        "                # Parse each line as a JSON object\n",
        "                doc = json.loads(line.strip())\n",
        "\n",
        "                # Yield a document dictionary suitable for indexing\n",
        "                # Adjust the field names based on your JSONL structure\n",
        "                yield {\n",
        "                    'docno': doc.get('id', ''),  # Document ID\n",
        "                    'text': doc.get('text', ''),  # Main text content\n",
        "                    'title': doc.get('title', ''),  # Optional title field\n",
        "                    # Add other fields as needed\n",
        "                }\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"Error parsing line: {e}\")\n",
        "                continue\n",
        "\n",
        "    # with open(f\"/content/corpus.jsonl\", \"r\") as f:\n",
        "    #     corpus = json.load(f)\n",
        "\n",
        "    # for doc in corpus:\n",
        "    #     # Create a dictionary with the document fields\n",
        "    #     yield {\n",
        "    #         'docno': doc['id'],\n",
        "    #         'text': doc['text'],\n",
        "    #         # Add other fields if available\n",
        "    #         'title': doc.get('title', ''),\n",
        "    #     }\n",
        "\n",
        "# Create the indexer\n",
        "# You can specify which fields to index and metadata to store\n",
        "indexer = pt.IterDictIndexer(\n",
        "    index_dir,\n",
        "    # Configure which fields to index (the content to search)\n",
        "    fields=['text', 'title',],\n",
        "    # Configure metadata (fields to retrieve but not search)\n",
        "    meta={'docno': 20, 'text': 4096}\n",
        ")\n",
        "\n",
        "# Run the indexing process\n",
        "indexref = indexer.index(fiqa_document_generator())\n",
        "\n",
        "# Print information about the created index\n",
        "index = pt.IndexFactory.of(indexref)\n",
        "print(f\"Index created with {index.getCollectionStatistics().getNumberOfDocuments()} documents\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baaec01e43f9>:5: DeprecationWarning: Call to deprecated function (or staticmethod) started. (use pt.java.started() instead) -- Deprecated since version 0.11.0.\n",
            "  if not pt.started():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21:57:55.991 [ForkJoinPool-1-worker-3] WARN org.terrier.structures.indexing.Indexer -- Adding an empty document to the index () - further warnings are suppressed\n",
            "21:58:16.700 [ForkJoinPool-1-worker-3] WARN org.terrier.structures.indexing.Indexer -- Indexed 39 empty documents\n",
            "Index created with 57638 documents\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrieve top 100 results using BM25"
      ],
      "metadata": {
        "id": "3neGfOCh6pc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyterrier as pt\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Initialize PyTerrier if not already started\n",
        "if not pt.started():\n",
        "    pt.init()\n",
        "\n",
        "# Paths to your data files\n",
        "train_path = \"train.tsv\"\n",
        "test_path = \"test.tsv\"\n",
        "dev_path = \"dev.tsv\"\n",
        "index_path = \"./fiqa_index\"  # Path to your previously created index\n",
        "\n",
        "# Load the qrels files with the proper column names\n",
        "def load_qrels(file_path):\n",
        "    qrels = pd.read_csv(file_path, sep='\\t',\n",
        "                        names=['qid', 'docno', 'relevance'],  # Named 'relevance' instead of 'score'\n",
        "                        header=0)  # Skip header row\n",
        "\n",
        "    # Convert to the format PyTerrier expects\n",
        "    qrels['qid'] = qrels['qid'].astype(str)\n",
        "    qrels['docno'] = qrels['docno'].astype(str)\n",
        "\n",
        "    return qrels\n",
        "\n",
        "train_qrels = load_qrels(train_path)\n",
        "test_qrels = load_qrels(test_path)\n",
        "dev_qrels = load_qrels(dev_path)\n",
        "\n",
        "print(f\"Loaded {len(train_qrels)} training relevance judgments\")\n",
        "print(f\"Loaded {len(test_qrels)} test relevance judgments\")\n",
        "print(f\"Loaded {len(dev_qrels)} development relevance judgments\")\n",
        "\n",
        "# Extract unique query IDs from qrels\n",
        "train_query_ids = train_qrels['qid'].unique()\n",
        "test_query_ids = test_qrels['qid'].unique()\n",
        "dev_query_ids = dev_qrels['qid'].unique()\n",
        "\n",
        "print(f\"Found {len(train_query_ids)} unique training query IDs\")\n",
        "print(f\"Found {len(test_query_ids)} unique test query IDs\")\n",
        "print(f\"Found {len(dev_query_ids)} unique development query IDs\")\n",
        "\n",
        "# Get the queries (we need query text for retrieval)\n",
        "# Do you have a separate file with query texts?\n",
        "# If not, we'll try to extract whatever text we can from your index\n",
        "\n",
        "# Load the index\n",
        "index = pt.IndexFactory.of(index_path)\n",
        "print(f\"Loaded index with {index.getCollectionStatistics().getNumberOfDocuments()} documents\")\n",
        "\n",
        "# Create dummy queries if you don't have actual query texts\n",
        "def create_dummy_queries(query_ids):\n",
        "    queries = pd.DataFrame({\n",
        "        'qid': query_ids,\n",
        "        'query': [f\"query_{qid}\" for qid in query_ids]  # Placeholder query text\n",
        "    })\n",
        "    return queries\n",
        "\n",
        "train_queries = create_dummy_queries(train_query_ids)\n",
        "test_queries = create_dummy_queries(test_query_ids)\n",
        "dev_queries = create_dummy_queries(dev_query_ids)\n",
        "\n",
        "# Create a BM25 retriever and set to retrieve top 100 results\n",
        "retriever = pt.BatchRetrieve(index, wmodel=\"BM25\", num_results=100)\n",
        "\n",
        "# Run retrieval on each query set\n",
        "train_results = retriever.transform(f\"results/{train_queries}\")\n",
        "test_results = retriever.transform(f\"results/{test_queries}\")\n",
        "dev_results = retriever.transform(f\"results/{dev_queries}\")\n",
        "\n",
        "# Save results in TREC format\n",
        "def save_results(results, output_file):\n",
        "    with open(output_file, 'w') as f:\n",
        "        for _, row in results.iterrows():\n",
        "            f.write(f\"{row['qid']} Q0 {row['docno']} {row['rank']} {row['score']} PyTerrier-BM25\\n\")\n",
        "    print(f\"Saved {len(results)} results to {output_file}\")\n",
        "\n",
        "save_results(train_results, \"train_results.txt\")\n",
        "save_results(test_results, \"test_results.txt\")\n",
        "save_results(dev_results, \"dev_results.txt\")\n",
        "\n",
        "# Example of evaluating retrieval against the qrels\n",
        "test_eval = pt.pipelines.Evaluate(test_results, test_qrels, metrics=[\"map\", \"ndcg_cut_10\", \"P_100\", \"recall_100\"])\n",
        "print(\"\\nTest evaluation results:\")\n",
        "print(test_eval)"
      ],
      "metadata": {
        "id": "JBSeKga16ouZ",
        "outputId": "045485c4-8c13-4f36-e5e6-40f54bca511e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-e66c526d96f0>:6: DeprecationWarning: Call to deprecated function (or staticmethod) started. (use pt.java.started() instead) -- Deprecated since version 0.11.0.\n",
            "  if not pt.started():\n",
            "<ipython-input-25-e66c526d96f0>:65: DeprecationWarning: Call to deprecated class BatchRetrieve. (use pt.terrier.Retriever() instead) -- Deprecated since version 0.11.0.\n",
            "  retriever = pt.BatchRetrieve(index, wmodel=\"BM25\", num_results=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 14166 training relevance judgments\n",
            "Loaded 1706 test relevance judgments\n",
            "Loaded 1238 development relevance judgments\n",
            "Found 5500 unique training query IDs\n",
            "Found 648 unique test query IDs\n",
            "Found 500 unique development query IDs\n",
            "Loaded index with 57638 documents\n",
            "Saved 0 results to train_results.txt\n",
            "Saved 0 results to test_results.txt\n",
            "Saved 0 results to dev_results.txt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "No results for evaluation",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-e66c526d96f0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;31m# Example of evaluating retrieval against the qrels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0mtest_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipelines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_qrels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ndcg_cut_10\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"P_100\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"recall_100\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nTest evaluation results:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyterrier/pipelines.py\u001b[0m in \u001b[0;36mEvaluate\u001b[0;34m(res, qrels, metrics, perquery)\u001b[0m\n\u001b[1;32m    800\u001b[0m     \"\"\"\n\u001b[1;32m    801\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No results for evaluation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqrels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mperquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No results for evaluation"
          ]
        }
      ]
    }
  ]
}